---
layout: post
title: "DEVIEW 2014를 다녀와서"
tags: ['일상']
date: 2014-10-01 01:33:00
---
# [DEVIEW](http://deview.kr) 2014를 다녀와서

네이버 데뷰를 다녀왔다. 개발자 컨퍼런스라는 곳에 가본 적이 없어서 한번 가보고 싶었던 것도 있고, 뭔가 다들 데뷰데뷰 하길래 나도 가야겠다 싶었다. 그리고 화룡점정은 김영후 님의 스위프트 세션. 스위프트에 관심은 계속 있었는데 막상 해볼 시간도 없고 의지도 없어서… 발표가 매우 듣고 싶었다.

데뷰2014는 잠실 롯데호텔월드 3층, 크리스탈 볼룸에서 열렸고 9월 29일, 30일 2일간 총 64개의 세션이 진행되었다. 잠실이 집에서 멀기는 했지만 역에서 바로 갈 수 있어 교통도 좋았고, 시설이 깔끔하게 잘 되어 있어 만족스러웠다. 아쉬웠던 점이라면 와이파이가 잘 안잡힌다는 것 정도? 개발자 컨퍼런스인 만큼 다들 노트북을 들고 오는데 와이파이를 제공했다면 좋았으리라 생각한다.

## 짧은 소감

이런 컨퍼런스가 처음이라, 듣고자 하는 세션을 잘못 골랐다는 생각이 들었다. 결론적으론, 그냥 그랬다. 최근에 데이터 사이언스 쪽에 계속 관심이 있었고 마침 데이터 사이언스 관련 세션이 많기에 데이터 사이언스 쪽으로 잔뜩 골라 들었다. 그랬더니 썩 아는 얘기가 대부분이고, 다 비슷비슷한 내용들이라 별 영양가가 없더라.

그래서 결론은, 이런 컨퍼런스를 가면 **잘 모르는 걸 들어라**. 관심분야를 들어 봐야 네가 아는 얘기만 할 것이다. 물론 개중에 조금 건지는 건 있겠지만.

## 세션별 소감 및 정리

들은 세션이 많지는 않지만 간단하게 적어본다. Day 1에서는 스위프트 세션밖에 듣지 못했다.  
정리는 단순히 발표 내용을 정리한 게 아니라 발표 내용에 대한 내 생각들을 정리한 것이므로 정확한 발표 내용을 알고 싶다면 데뷰 홈페이지에서 동영상과 발표자료를 보도록 하자.

### 스위프트 프로그래밍 언어

위에서도 언급했지만 스위프트에 관심이 많아 이번 데뷰에서 가장 기대했던 세션이었지만 조금 실망했다. 뭐랄까, 너무 실무 레벨의 느낌이었다. 조금 더 추상적으로 스위프트의 특징과 장단점을 자세히 소개해 주었다면 더 좋았을 것 같다.

  * 오브젝티브C 써라
    * 스위프트 쓰기에는 아직 과도기.
    * 기본 코코아 프레임워크들이 오브젝티브C인 한…
  * 스위프트도 쓸 순 있다
    * 발표자인 김영후 님이 이미 스위프트로 프로젝트를 다수 진행중이셨다.
    * 최신 언어인 만큼 강력한 기능들이 많긴 함.

### Developing context-aware applications

구글 나우 따위의 지능형 개인비서(intelligent assistants)는 현재 상황을 인지하고 그로써 사용자에게 새로운 정보를 제공한다. 이에 대한 세션이었는데 가장 먼저 느낀점은 가능하면 영어 세션은 듣지 말자. 동시통역이 제공되고 퀄리티가 훌륭(사실 동시통역을 많이 들어보진 못해서 평가할 수는 없겠지만)하지만, 아무리 그렇다고 해도 정신이 없고 듣기가 힘들다. 물론, 이 세션 발표자가 좀 정신없이 발표하기도 한 것 같지만.

  * knowledge graph
    * 엔티티간 관계도를 널리지 그래프라고 하더라. 현재 진행중인 뉴스 추천 프로젝트에서 엔티티간 관계도를 구성할지 말지 고민중인데 역시 이미 다들 하고 있었다.
    * 구글이 보유한 널리지그래프의 엔티티 수가 5억개라나…
    * 야후는 천만개밖에 안 되지만, 이게 다 사람이 입력한 거란다.
  * 세가지 분야
    * Speech Recognition
    * Computer Vision
    * Language Understanding
  * 마무리는 자기들 서비스 데모였는데
    * 보이스 기반이었다. Siri를 생각하면 간단.
    * 영어라 그런지 잘 작동하더라. 당연히 잘 작동하겠지만 생각보다 더 잘되는 것 같아서 신기했다.

### Deep Learning at NAVER

위에서 잘 모르는 걸 들어야 한다고 했는데, 내게는 스위프트와 더불어 이 딥러닝 세션이 딱 그러했다. 머신러닝에 대해 공부는 했지만 그중에서도 요새 대두되고 있는 딥러닝에 대해서는 아는 바가 적었는데 이번 기회에 이야기를 들을 수 있어 좋았다.

  * 왜 갑자기 딥러닝이 대세가 되었는가?
    * 잘 되니까. 20%정도의 향상.
    * 20%가 별거 아닌 거 같아 보일 수 있지만 엄청난거다. 발표자료를 보면 알겠지만 근 10년간 발전이 없던 Speech Recognition 정확도가 비약적으로 상승함.
  * 그럼 왜 딥러닝이 부활했는가? (왜 잘 되는가?)
    * New Algorithms: 딥러닝은 Overfit이 문젠데 이를 방지하기 위한 새로운 알고리즘 등장.
    * Big Data: 딥러닝은 데이터셋이 많이 필요하다
    * Hardware: 빅데이터를 분석하기 위한 하드웨어 등장
  * 뉴럴 네트워크
    * 알겠지만 딥러닝이 결국 멀티레이어 뉴럴 네트워크임.
    * 장점
      * prior knowledge가 필요없다.
      * 데이터에 Overfitting.
        * 원래는 단점이었지만, 빅데이터에서는 장점이 된다.
        * 노이즈를 그대로 학습함으로써 overfit이 overfit이 아니게 되는 효과.
        * 물론 지나친 노이즈는 제거해야 함.
  * Learning
    * supervised learning (정답이 있는 데이터)
    * semi-supervised learniing
      * supervised learning + unsupervised learning
    * supervised learning을 하고 싶지만 정답데이터는 결국 사람이 만들어야 하고 이게 어렵다. 그래서 선택하는 것이 semi-supervised learning.
  * 이러니 저러니 해도 딥러닝이 절대반지는 아니고 한참 멀었다는 결론으로 마무리.

### Map-D: A GPU Database For Interactive Big Data Analytics

나는 GPU가 그냥 그래픽 카드 안에 들어 있는 CPU를 지칭하는 줄 알았다. 그게 아닌 걸 여기서 처음 알게 됨 -_-;;  
<http://mapd.csail.mit.edu/tweetmap-desktop/> : map-d 데모.

수십억건의 트윗 데이터를 밀리세컨드 단위로 분석한다고 하는데, 정말 어마어마하게 빠르긴 하다.  
The world's fastest database라고 말하는데 간지터짐.

GPU + In-memory Databse.  
GPU는 CPU에 비해서 메모리가 부족하므로 프리 캐싱을 한다. 물론 그래도 CPU메모리로 갔다와야 하는 경우가 발생하고 그럴 때는 빠르지 않음. 추후 관련 기술이 나와 개선될 것으로 보임.

### Web &amp; Health 2.0. 회사에서의 data science란?

별 내용이 없었다. 데이터의 프리프로세싱을 많이 강조했는데 지극히 당연한 얘기라고 생각했다. 데이터마이닝의 70%는 프리프로세싱이라는 얘기도 있을 정돈데…  
Preprocessing을 Preparation(준비) 또는 Munging(변경) 이라고 말씀하신 것 정도가 특기사항. 발표를 듣다 보면 Cleaning이라고도 하시는 듯.

  * 텍스트 데이터의 de-duplication
    * 음식 데이터 예시였는데, 클러스터링과 비슷하지만 다르다.
    * semantic을 사용하지 않는다 -&gt; 자장면과 짬뽕은 굉장히 비슷하지만 다른 duplicate로 본다.
    * 결국 클러스터링 아닌가? 더 공부가 필요할 듯하다.
  * Edit distance
    * 두 스트링을 비교할 때 거리를 계산하는 방법.
    * 예전에 알고리즘 공부할 때 했던 바로 그것.
      * Dynamic Programming
    * 이러한 알고리즘들을 잘 아는 게 (실리콘밸리에서는)중요하다고 강조.
  * word2vec
    * 위 딥러닝 세션에서 잠시 보여줬던 건데, 여기서 이게 word2vec이라는 걸 알았다. 구글이 만든 라이브러리.
    * word 간의 거리를 계산해 준다.
    * king - man + woman이라는 게 가능하다. king에서 man이라는 특징을 빼고 woman이라는 특징을 더하면 queen이 나온다.

### LinkedIn의 Data Science - 왜 '과학'인가?

  * 빅데이터의 3요소 + 2목표
    * 3요소
      * 빅데이터
      * 툴 : 하둡, 타조, 스파크 등의 빅데이터를 다루는 툴.
      * 방법론
        * 이 바로 데이터 사이언스.
    * 2목표
      * Data Analytics
        * Data -&gt; Information 이라는 데이터마이닝의 기본적인 목표.
        * 데이터를 분석하여 데이터로부터 인포메이션을 추출한다.
      * Data Product
        * 이 인포메이션을 기반으로 사용자에게 유의미한 프로덕트(서비스)를 제공.
  * 데이터 사이언스란?
    * Data -&gt; Information
    * 과학적 방법론을 사용한다.
      * 가설 -&gt; 모델링 -&gt; 실험 -&gt; 검증
      * 그래서 사이언스!

## 놓쳤지만 동영상으로 보고 싶은 세션들

### 볼 세션들

  * 아이비컨과 공유기 해킹을 통한 인도어 IOT 삽질기
    * 아이비컨도 들어가 있고, IOT도 들어가 있어서 관심이 간다. 최근에 가장 핫한게 IOT 일텐데 정작 이번 데뷰에서 IOT 세션은 못 들어서 아쉬웠다.
    * 특히 페이스북에서 누군가가 추천한 걸 봐서…
  * Docker로 보는 클라우드 서버 운영의 미래
    * Docker + 클라우드 서버. 둘다 관심있는 키워드.
  * 검색엔진의 패러다임 전환: 빅데이터분석과 검색의 융합
  * Live Broadcasting 추천 시스템
  * Python에서의 동시성/병렬성
  * 시즌2 : 멀티쓰레드 프로그래밍이 왜이리 힘드나요?

### 볼 수도 있는 세션들

  * WebRTC 개발, 현재, 그리고 미래
  * Realm: a database for Android &amp; iOS
  * 모바일 앱 크래시!! 네이버에서는 어떻게 수집하고 보여줄까요?
  * 지금까지 상상한 표현의 한계를 넘자-webGL
  * 모바일 P2P 미디어 스트리밍 방법
  * 앱 세상에서 HTML5 생존기: HTML5 기반 모바일 단말용 게임 개발 및 최적화
  * Automated Recognition of Alzheimer's Disease from Wearable Devices: Big Brain Data and Big Visual Data
  * ElasticSearch 성능 최적화
  * Apache Pig를 위한 Tez 연산 엔진 개발하기
  * Big Data Launching Episodes
  * Solving large scale data problems with OpenStack 


[Tistory 원문보기](http://khanrc.tistory.com/43)
