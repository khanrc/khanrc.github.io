---
layout: post
title: "얼굴 인식 및 사진 똑바로 세우기"
tags: ['iOS']
date: 2015-07-23 01:29:00
---
지금 만들고 있는 [fluttr](http://fluttr.me) 앱에 갤러리에서 사진을 불러오고, 얼굴인식을 해서 프레임을 씌워주는 기능이 필요하다. 얼굴인식 API는 iOS 5.0 부터 애플이 자체적으로 지원하고 있다.

### 사진 똑바로 세우기
    
    
    // find orientation
    UIImageOrientation orientation = UIImageOrientationUp;
    NSNumber *orientationValue = [asset valueForProperty:@"ALAssetPropertyOrientation"];
    if(orientationValue != nil)
        orientation = [orientationValue intValue];
    NSLog(@"orientation : %ld", orientation);
    
    UIImage *fullImage = [UIImage imageWithCGImage:asset.defaultRepresentation.fullResolutionImage scale:1.0 orientation:orientation];

`ALAsset`으로부터 사진의 방향을 알아내서 똑바로 세워서 fullImage에 넣는 코드다. 이렇게 하지 않고 그냥 어셋에서 불러와서 화면에 띄우면 방향이 다 뒤죽박죽이다. 아마 찍을 때의 방향을 보존하는 것 같다.

**참고**   
[UIImage from ALAsset: getting the right orientation](http://biasedbit.com/alasset-image-orientation/)   
[stackoverflow; iOS - UIImageView - how to handle UIImage image orientation](http://stackoverflow.com/questions/8915630/ios-uiimageview-how-to-handle-uiimage-image-orientation)

### 얼굴 인식하기

iOS 5.0 부터 애플이 [빌트인 API](https://developer.apple.com/library/ios/documentation/GraphicsImaging/Conceptual/CoreImaging/ci_detect_faces/ci_detect_faces.html)를 제공한다. 공식 문서를 그대로 보고 했더니 잘 안 되서 삽질을 좀 했다.
    
    
    // face recognition
    CIImage* image = [CIImage imageWithCGImage:fullImage.CGImage];
    
    CIDetector* detector = [CIDetector detectorOfType:CIDetectorTypeFace
                                              context:nil
                                              options:@{CIDetectorAccuracy: CIDetectorAccuracyLow}];
    
    NSArray* features = [detector featuresInImage:image];
    NSLog(@"[Face Recog] %@", features);
    

삽질을 한 이유는 여러가지지만, 그 중 하나는 `CIImage`, 즉 `CoreImage`와 `UIKit`간의 다른 좌표계산 방법이다. UIKit은 왼쪽 위부터 좌표를 계산하지만 CoreImage는 왼쪽 아래가 기준이다. 따라서 변환이 필요하다.
    
    
    CGAffineTransform transform = CGAffineTransformMakeScale(1, -1); // CIImage와 UIKit은 좌표기준이 달라서 변환해 주어야 함
    transform = CGAffineTransformTranslate(transform, 0, -fullImage.size.height);

그리고 나서 내가 이미지를 보여줄 이미지뷰의 사이즈와 fullImage의 사이즈가 다르므로 이것도 맞추어 준다. 이 작업도 CGAffineTransform으로 하려고 했는데 실패해서 그냥 나누어주었다.
    
    
    for(CIFaceFeature *faceFeature in features){
        CGRect faceRect = CGRectApplyAffineTransform(faceFeature.bounds, transform);
        UIView *faceView = [[UIView alloc] initWithFrame:faceRect];
        faceView.layer.borderWidth = 1;
        faceView.layer.borderColor = [[UIColor redColor] CGColor];
        float widthRatio = fullImage.size.width / imagev.width;
        float heightRatio = fullImage.size.height / imagev.height;
        faceView.x /= widthRatio;
        faceView.width /= widthRatio;
        faceView.y /= heightRatio;
        faceView.height /= heightRatio;
        [imagev addSubview:faceView];
    }

끝!

  


![](http://cfile4.uf.tistory.com/image/2216264C55AFC51638F30B)

(은가은이라는 신인 가수 사진으로 <http://news.donga.com/3/all/20140204/60577578/9> 에서 가져왔다)

  


**참고**   
[CoreImage and UIKit coordinates](http://nacho4d-nacho4d.blogspot.kr/2012/03/coreimage-and-uikit-coordinates.html)   
[Tutorial: Easy Face Detection With Core Image In iOS 5 (Example Source Code Provided)](https://maniacdev.com/2011/11/tutorial-easy-face-detection-with-core-image-in-ios-5)


[Tistory 원문보기](http://khanrc.tistory.com/112)
